План защиты лабораторной работы по Lucene (технический вариант)
===============================================================

1) Введение
-----------
- Apache Lucene — это библиотека для полнотекстового поиска. Она лежит в основе систем вроде Apache Solr и Elasticsearch.
- В лабораторной реализованы четыре части:
  1. IndexBuilder — создание индекса из текстов.
  2. IndexInspector — просмотр структуры индекса и postings.
  3. SearchCLI — интерактивный поиск с подсветкой.
  4. Бенчмарки (JMH) — замер производительности.

2) Индексация (IndexBuilder)
----------------------------
- Источники: файлы `.txt` из папки dataset.
- Для каждого файла создаётся документ с полями:
  - `contents` — текст, анализируемый StandardAnalyzer, сохраняется с частотами, позициями и оффсетами. Это важно для подсветки.
  - `path` — путь к документу, StringField (не анализируется, но хранится).
  - `snippet_source` — полный текст, чтобы извлекать сниппеты.
- Compound file system:
  - Аргумент `--cfs=true/false` задаёт, будут ли сегменты храниться в одном файле или в нескольких.
  - Пример запуска:
    ```
    ./gradlew run --args="dataset index --cfs=true"
    ```
  - Здесь:
    - `dataset` — входная папка с документами.
    - `index` — выходная папка для индекса.
    - `--cfs=true` — включить compound files.

3) Инспекция индекса (IndexInspector)
-------------------------------------
- Показывает список файлов индекса, суммарные размеры по расширениям.
- Выводит статистику по сегментам:
  - количество документов (numDocs, maxDoc),
  - для каждого поля — наличие частот, позиций, оффсетов.
- Если указан термин, выводит postings: docID, позиции и оффсеты.
- Пример запуска:
        ./gradlew run --args="index contents lucene"
- `index` — путь к индексу,
- `contents` — поле,
- `lucene` — термин.
- По результатам видно, что термин встречается в каждом документе, и Lucene хранит его позиции и диапазоны символов.

4) Поиск с подсветкой (SearchCLI)
---------------------------------
- Работает через QueryParser, поддерживает стандартный синтаксис Lucene.
- UnifiedHighlighter использует оффсеты, чтобы выделять термы в тексте.
- Пример запуска:
        ./gradlew run --args="index contents --topK=10"
- `index` — папка индекса,
- `contents` — поле,
- `--topK=10` — количество результатов.
- В режиме REPL пользователь вводит запросы:
- `"Apache"` → подсветка терма Apache в doc2.txt.
- `"full text"~3` → поиск слов «full» и «text» в радиусе 3 позиций.
- `search AND analyzer` → булевый запрос.

5) Бенчмарки JMH
----------------
- IndexingBenchmark:
- Замеряет скорость индексации документов.
- Аргументы: datasetDir, useCompound.
- SearchLatencyBenchmark:
- Замеряет среднюю латентность одиночного поиска.
- Аргументы: datasetDir, field, queriesFile, topK, useCompound.
- Пример запуска через JmhRunner:
        ./gradlew run
- Результаты:
- Индексация: ~75k операций/с.
- Поиск: ~3 микросекунды/запрос.
- Объяснить: такие цифры возможны только на маленьком датасете, в реальности латентность больше.

6) Теоретическая часть
----------------------
- Lucene хранит документы в сегментах. Сегменты не изменяются, только добавляются новые.
- Поиск идёт через postings: для каждого терма хранится список docID и позиций.
- Подсветка (highlighting) работает за счёт сохранённых оффсетов.

7) Выводы
---------
- Лабораторная показывает полный цикл работы Lucene: индексирование, просмотр структуры, поиск и подсветку, замеры производительности.
- Понимание устройства postings и структуры индекса — ключевая часть.
- Бенчмарки демонстрируют методику оценки производительности.

8) Дополнительные вопросы и ответы
----------------------------------
1. Вопрос: Зачем нужны оффсеты?
 Ответ: Чтобы можно было подсветить терм в исходном тексте. Без оффсетов подсветка невозможна.

2. Вопрос: Чем отличаются path и contents?
 Ответ: path — не анализируется, хранится как есть; contents — анализируется, токенизируется и индексируется с позициями.

3. Вопрос: Что делает параметр useCompound?
 Ответ: Определяет, хранить ли сегмент в одном файле (удобнее для ФС) или в нескольких (может быть быстрее при больших объёмах).

4. Вопрос: Почему результат поиска имеет score?
 Ответ: Score рассчитывается алгоритмом BM25, учитывает частоту терма в документе и обратную частоту по коллекции.

5. Вопрос: Можно ли обновить документ в Lucene?
 Ответ: Прямого обновления нет. Lucene удаляет старый и добавляет новый документ.

6. Вопрос: Почему результаты бенчмарка такие маленькие?
 Ответ: Индекс очень маленький, всё помещается в память, поэтому латентность микросекундная. Для больших коллекций значения будут выше.

7. Вопрос: Как Lucene справляется с удалениями?
 Ответ: Помечает документ как удалённый в сегменте. Реальное удаление происходит при слиянии сегментов (merge).

8. Вопрос: Что будет, если отключить compound files?
 Ответ: Индекс будет состоять из множества мелких файлов. Это может ускорить или замедлить операции в зависимости от файловой системы.

9. Вопрос: Какие классы отвечают за построение и поиск?
 Ответ: IndexWriter — за индексацию, IndexReader и IndexSearcher — за поиск.

10. Вопрос: Как изменить количество возвращаемых результатов?
  Ответ: Через параметр --topK в SearchCLI или через topK в SearchLatencyBenchmark.
